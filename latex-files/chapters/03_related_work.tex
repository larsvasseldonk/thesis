In this section we conduct a literature review to analyse techniques that present a novel way to decompose monolithic software into microservices. This section first explains the utilised search strategy and justifies the qualitative assessment used to characterise the discovered papers. After this, we dive into the results of the literature study.

\section{Search strategy}\label{s:search_strategy}
To start the search process, we have formed the following search string: 

\begin{itemize}
    \item[] \textit{("microservice*" OR "micro-service" OR "micro service") [AND "monolith"] [AND ("refactor" OR "transform" OR "migrat*" OR "decompos*" OR "partition*")]}
\end{itemize}
This search string is a mix of the ones used in \cite{fritzsch2018monolith} \cite{ponce2019migrating} and tells us that the body of the source needs to contain at least the words "microservices" (or one of its variations), "monolith" and "refactor" (or one of its synonyms). \par
The search queries are conducted on the three most frequently used computer science scientific libraries and indexing systems \cite{fritzsch2018monolith}: ACM Digital Library, IEEE Xplore, and Google Scholar. We have chosen these libraries since they have been proven to be most relevant for literature reviews in the software engineering domain \cite{petersen2015guidelines}. \par
To limit the results, we have created certain selection criteria. At first, the articles need to be peer-reviewed and written in English. Moreover, the abstract of the article needs to clearly show that it proposes a novel microservices decomposition technique with some degree of automation. This means that techniques that aim to search for candidate microservices manually are excluded from the review. At last, sources that do not perform static (e.g. dependency or semantic analysis) or dynamic analysis to aggregate input data for the decomposition process are filtered out. This means that model-driven techniques that only take design elements as input are excluded from the literature review. Also, techniques that exclusively focus on evolutionary data are not selected in the literature review. \par
We also have employed snowballing to make sure all the relevant articles are found. The snowballing procedure is recommended by \citeauthor{wohlin2014guidelines} \cite{wohlin2014guidelines} for literature reviews and has two variants. The first one, forward snowballing, identifies new papers that have cited the examined paper. The other one, backward snowballing, finds older papers that are referred by the examined paper. The literature review was conducted on the first of March 2021, and the results are described in section \ref{s:literature_results}.

\section{Justification of qualitative assessment}\label{s:justification_assessment}
During the search process, we have discovered 14 relevant articles that satisfy the selection requirements. An overview of the selected articles is given in Table \ref{tab:reviewed_papers} on page \pageref{tab:reviewed_papers}. To differentiate between the decomposition techniques, we performed a qualitative assessment. In this assessment, we aim to identify certain characteristics in each decomposition technique, such as the input data that is used. The characteristics on which the articles are reviewed are justified below:

\begin{itemize}
    \item \textbf{Input data.} This describes the kind of input data that is used to guide the decomposition. The raw input data is used to aggregate certain coupling information. 
    \item \textbf{Coupling data.} The coupling data, aggregated from the raw input data, describes how closely related code entities are. The different types of coupling data are explained in Section \ref{s:information_views}. Due to limited space in the table, we use the following acronyms:
    \begin{itemize}
        \item SD: Structural Dependencies
        \item FO: Fan-Out similarity
        \item EC: Evolutionary Coupling
        \item CO: Code Ownership
        \item SS: Semantic Similarity
        \item DC: Dynamic Coupling
    \end{itemize}
    \item \textbf{Decomposition method.} The decomposition method describes which clustering technique (algorithm) is used to decompose the monolith into a suitable set of microservices
    \item \textbf{Validation type.} This shows how the effects of the implemented techniques are investigated. It validates the quality of the approach. There are various validation types that can be used, such as measuring the quality with microservice (MS) metrics, comparing the result to an expert decomposition, comparisons to state-of-the-art methods, etc.
    \item \textbf{Supported language.} This explains the programming languages the technique supports. We assume that a programming language is supported when it is used on at least one application during validation.
\end{itemize}

In Table \ref{tab:summary_papers} on page \pageref{tab:summary_papers}, a summary of the qualitative assessment is given. The results of the qualitative assessment are given in the next section.

\input{tables/reviewed_papers}
\input{tables/summary_papers}

\section{Literature review results}\label{s:literature_results}
As mentioned before, we have discovered 14 papers that relate to the process of identifying microservices from monolithic software. In this section, each paper is discussed. \par

\citeauthor{al2021microservice} \cite{al2021microservice} used static analysis to extract methods from classes in the source code of the monolith and subsequently convert them into code embeddings using the code2vec model \cite{alon2019code2vec}. These code embeddings represent the source code as a bag of weighted abstract syntax tree (AST) paths and have the ability to capture the semantics of the source code. The code embeddings are fed to the Affinity Propagation clustering algorithm to generate suitable microservices. The quality of the decomposition is examined by applying microservice specific measures and subsequently comparing them to \cite{jin2018functionality, saidani2019towards}.\par
\citeauthor{brito2021identification} \cite{brito2021identification} recently proposed a technique to decompose Java systems based on structural dependencies and semantic similarity. The structural dependencies are aggregated at class-level and used to derive an undirected graph. The semantic information embedded in the system's source code is used to get a topic probability distribution for each identified class. The cosine similarity between the topic distributions determines the weight of association between classes in the graph. The weighted graph is then clustered according to the Louvain algorithm introduced by \citeauthor{blondel2008fast} \cite{blondel2008fast}. The quality of the resulting candidate services is determined by measuring the independence of functionality. Also the Structural Modularity Quality (SMQ) and Conceptual Modularity Quality (CMQ) metrics are used to quantify the quality of the decomposition. The approach is validated on 200 Java Spring applications collected from GitHub. \par
\citeauthor{de2018function} \cite{de2018function} analyses the source code and database structure in order to discover structural dependencies. More specifically, they analyse Create-Read-Update-Delete (CRUD) operations to obtain relationships between database tables. The obtained information from that static analyser is merged with dynamic information into a weighted dependency graph. They used a graph-based clustering algorithm to find cohesive clusters. The resulting microservices are actually implemented on two test applications to evaluate the execution efficiency in terms of scalability and availability. \par
\citeauthor{eski2018automatic} \cite{eski2018automatic} parses the codebase to obtain AST paths and perform evolutionary analysis over the version control system (VCS) to detect changes between two consecutive commits. The two extracted features are merged together into a software relation graph. This graph is clustered by applying the Fast Community graph clustering algorithm. The quality of the decomposition is determined by computing the MoJo similarity between the identified candidate microservices and an expert decomposition. \par
\citeauthor{kamimura2018extracting} \cite{kamimura2018extracting} extracts program call and data access dependencies by analysing the source code. They specify how important code elements like entry points, data, program calls, and read/write access can be detected in Java and Cobol programs. For example, entry points in Java are detected by classes with "@Control" annotations, while data elements are recognised by classes with "@Entity" annotations. The extracted information is represented in a graph that is clustered according to the Software Architecture Finder (SArF) algorithm. To validate the approach, the Spring Boot Pet Clinic application that has both a monolith and microservice version is used. The microservices identified by the SArF algorithm are manually compared to the ones in the microservice version. The approach is also evaluated on an industry application. \par
The approach by \citeauthor{lohnertz2020steinmetz} \cite{lohnertz2020steinmetz} uses an algorithm that recursively walks down the classes and methods in the program to build a dependency graph. The weights between classes are calculated through the Response For a Class (RFC) metric. They also extract semantic information by parsing domain-specific terms from the source code. This results in a document-term matrix and is used to supplement the dependency graph. At last, they mine the VCS in order to understand code changes that are made during the project. The information extracted from this analysis is also merged into the dependency graph. The graph is constructed for 14 Java application and then clustered with seven different graph-based clustering algorithms. The quality of the decomposition is measured by a set of metrics consisting of input fidelity, general clustering quality, mean cluster factor and modularity.  \par
\citeauthor{mazlami2017extraction} \cite{mazlami2017extraction} introduces the Microservice Extraction Model (MEM) that is based on three extraction strategies: logical coupling, semantic coupling, and contributor coupling. The logical coupling strategy analyses the revision history to discover which classes change together. The semantic strategy looks to the vocabulary of classes and the contributor strategy focuses on the ownership of code fragments from the monolith. The code ownership is also extracted from the revision history controlled by the VCS. The ownership of code reveals information about team structures and communication patterns between teams. This information is interesting when an organisation wants to follow the microservice principle of having cross-functional teams organised around domain and business capabilities. The three information sources are combined in an undirected weighted graph and are clustered according to the Minimum Spanning Tree (MST) algorithm. They validated their approach on 19 application written in Java, Python and Ruby. The quality of the decomposition is measured by two custom metrics: the team size reduction ratio (TSR) and the average domain redundancy (ADR). \par
The decomposition technique introduced by \citeauthor{matias2020determining} \cite{matias2020determining} combines static code analysis and runtime analysis. At first, the source code is analysed to obtain the dependency graph. The static analyser also computes weights, which is a function of the number and quality of connections between two code entities. The static analysers subsequently update the weights according to the interaction between two entities. The graph is constructed for an industry Python application built with the Django framework. The Girvan-Newman algorithm is used to cluster the weighted graph. The resulting candidate microservices are compared to the ones obtained by the model-driven ServiceCutter \cite{gysel2016service} approach. They also performed a survey with experts to test the applicability of the approach. \par
\citeauthor{saidani2019towards} \cite{saidani2019towards} introduces a novel decomposition technique, called MSExtractor, by considering the microservice extraction problem as a multi-objective combinatorial optimisation problem. They aim to minimise coupling and maximise cohesion by extracting structural dependencies embodied in the source code. The Non-dominated Sorting Genetic Algorithm II (NSGA-II) is used to find the most optimal microservice candidates. The approach leverages four specific microservice metrics conceived by \cite{jin2018functionality}. These metrics are then used to compare the resulting decomposition with the ones obtained by FoME \cite{jin2018functionality}, MEM \cite{mazlami2017extraction}, and LIMBO \cite{andritsos2005information}. \par
The approach by \citeauthor{selmadji2018re} \cite{selmadji2018re} focuses on information derived from static analysis. They aim to cluster classes from object-oriented source code based on their dependencies. However, the approach differentiates itself from others by introducing a set of well-defined functions to measure the quality of microservices. This function is based on the "focused on one function" characteristic, structural and behavioural autonomy and data autonomy of the microservice. These metrics are used to validate the approach on three Java applications.
Another proposed technique by \citeauthor{selmadji2020monolithic} \cite{selmadji2020monolithic} tries to enhance the clustering result by incorporating expert recommendations. Recommendations can be made about the number of microservices or about the main class of the microservice. This main class represents the functional core of the microservice. The quality of the resulting decomposition is determined by a qualitative assessment. In this assessment, experts have to classify each microservice as "excellent", "good', or "bad". \par
\citeauthor{nunes2019monolith} \cite{nunes2019monolith} proposes an approach that focuses itself around the transactional context rather than the structural domain of domain entities (e.g. classes). The static analysis is used to get insights into the domain entities that are accessed by the controllers. A controller corresponds to the execution of a functionality. The approach computes the weights between two entities in terms of similarity. This means that pairs of entities that are assessed by the same controller obtain a higher weight. The data is represented in a call graph and clustered with a hierarchical clustering algorithm. The resulting dendrogram is cut on four different points to get four distinct decompositions. The quality is of each decomposition determined by applying certain internal measures and by comparing it to an external decomposition obtained by Structure101. The approach restricts itself to applications that follow the model-view-controller (MVC) architectural style. \par
There are also two approaches that only focus on extracting information from the monolith at runtime. \par
\citeauthor{jin2018functionality} \cite{jin2018functionality} exclusively uses dynamic analysis to extract features from the system. They use two types of log traces: method-level and class-level execution traces. A method-level log trace presents the method-calling relation and invocation order. The class-level log trace shows which classes contribute to the same functional execution. The extracted traces are used in a self-designed execution trace algorithm to discover microservice candidates. The approach also defines five quality metrics that express the functional independence of the decomposition. They used these metrics to compare their approach to three state-of-the-art methods: LIMBO \cite{andritsos2005information}, WCA \cite{chatterjee2002wca}, MEM \cite{mazlami2017extraction}. The proposed approach is called Functionality-oriented Microserice Extraction (FoME). \par
In \citeauthor{jin2019service} \cite{jin2019service} the FoME technique is extended by taking into account both syntactic information (dependencies) and semantic information embedded in the execution traces. This new technique is called the Functionality-oriented Service Candidate Identification (FoSCI) framework and is code-free, meaning that it only relies on execution traces gathered from the running system. Based on the syntactic and semantic information, the approach identifies functional atoms, each being a coherent and minimal functional unit. These functional atoms are then clustered by optimising four objective functions - maximising the intra-connectivity (cohesion) and minimising the inter-connectivity (coupling) for both structural and semantic information - by applying the Non-dominated Sorting Genetic Algorithm II. After this, each identified candidate microservices is further analysed to detect potential interface classes and operations that can be published. The quality of the decomposition is measured by eight metrics assessing three aspects: the independence of functionality, the modularity, and the independence of evolvability. The approach is validated on six Java web applications and compared to LIMBO \cite{andritsos2005information}, WCA \cite{chatterjee2002wca}, MEM \cite{mazlami2017extraction}. \par
\citeauthor{zhang2020automated} \cite{zhang2020automated} also uses runnable programs as only required information source. They collaboratively analyse both the collected execution logs and performance-monitoring log. The execution logs are required to identify code entities and invocations between them. The performance logs are used to aggregate the average data used by each class. This information is merged together into a class-to-class relation evaluation matrix. The matrix is used as input for the genetic-based clustering algorithm. They use a genetic algorithm in order to optimise three objective functions simultaneously. The approach is validated by comparing it to an authoritative decomposition and a decomposition made by FoSCI \cite{jin2019service}.

\section{Observations}\label{s:literature_review_observations}
In the previous section, we analysed and described the characteristics of several related decomposition techniques. When examining this work, the following observations are made:

\begin{itemize}
    \item The most utilised source of information is the system's source code. Some of them use source code exclusively \cite{al2021microservice, brito2021identification, kamimura2018extracting, nunes2019monolith, saidani2019towards, selmadji2018re} while others extend it with other sources of information like log files \cite{de2018function, matias2020determining}, the revision history \cite{eski2018automatic, lohnertz2020steinmetz, mazlami2017extraction} or expert recommendations \cite{selmadji2020monolithic}. In contrast, only three approaches \cite{jin2018functionality, jin2019service, zhang2020automated} restrict themselves to the use of only execution traces obtained from the running system.
    \item The majority of the researchers focuses on hierarchical \cite{jin2018functionality, kamimura2018extracting, nunes2019monolith, selmadji2018re, selmadji2020monolithic} or graph-based clustering algorithms \cite{al2021microservice, brito2021identification, de2018function, eski2018automatic, lohnertz2020steinmetz, matias2020determining, mazlami2017extraction}. There are only three techniques that employ genetic algorithms \cite{jin2019service, saidani2019towards, zhang2020automated} to search for suitable microservices. They all make use of the Non-dominated Sorting Genetic Algorithm II (NSGA-II) introduced by \citeauthor{deb2002fast} \cite{deb2002fast}.
    \item We can distinguish three ways of measuring the quality of the derived microservice decomposition. At first, the quality can be monitored by computing the similarity to an expert decomposition. This expert decomposition (also called authoritative decomposition or golden standard) is mostly obtained manually from experts working with the software. Another option is to take an application that has both a monolith and microservice version. The monolith version is then processed, and the results are compared to the microservice version. These first two are considered external since a comparison is made to an external decomposition. A third way to measure the quality of the decomposition is by computing the internal structure of the microservices. To quantify the internal quality, researchers have proposed various microservice specific metrics. 
    \item Although many microservice specific metrics to measure the internal quality of the microservices have been proposed, there does not seem to be a consistent use among them in the community. Below we summarise a few metrics that have been introduced:
    \begin{itemize}
        \item Number of Singleton Clusters (NSC), and Maximum Cluster Size (MCS) by \cite{nunes2019monolith}.
        \item The Modularity Quality (MQ) introduced by \citeauthor{mancoridis1998using} \cite{mancoridis1998using}. This metric is extended by \cite{jin2019service} to get the Structural Modularity Quality (SMQ) and Conceptual Modularity Quality (CMQ).
        \item The functional independence of microservices is measured by five metrics \cite{jin2018functionality}: cohesion at domain level (CHD), cohesion at message level (CHM), interface numbers (IFN), operation numbers (OPN), and interaction numbers (IRN). The CHD and CHM measure the functional cohesion of microservices while IFN, OPN and IRN measure the coupling between microservices.
        \item Independence of evolvability, quantified by three metrics \cite{jin2019service}: internal co-change frequency (ICF), external co-change frequency (ECF), and ratio to ECF and ICF (REI). 
        \item In \cite{lohnertz2020steinmetz}, the input fidelity is used to measure the percentage of classes that are covered given an input.
    \end{itemize}
    \item Even though there is not a consistent use, the functional independence measures (or a subset thereof) are utilised the most throughout the related work \cite{al2021microservice, jin2018functionality, jin2019service, saidani2019towards, brito2021identification}.
    \item To quality of the decomposition is most frequently measured externally in which the results are compared to a golden standard (expert decomposition) \cite{eski2018automatic, kamimura2018extracting, selmadji2018re, selmadji2020monolithic, zhang2020automated} or to comparative techniques \cite{al2021microservice, jin2018functionality, jin2019service, matias2020determining, saidani2019towards} or both \cite{nunes2019monolith, zhang2020automated}. The most frequently used comparative technique is the Microservice Extraction Model (MEM) proposed by \citeauthor*{mazlami2017extraction} \cite{mazlami2017extraction}.
    \item Most of the techniques validate their approach on Java written applications. JPetstore\footnote{https://github.com/mybatis/jpetstore-6} and SpringBlog\footnote{https://github.com/Raysmond/SpringBlog} are two open-source applications written in Java that are in particular often used in the community \cite{al2021microservice, brito2021identification, jin2018functionality, saidani2019towards}. Only two decomposition techniques are validated on non-Java applications \cite{matias2020determining, mazlami2017extraction}.
\end{itemize}